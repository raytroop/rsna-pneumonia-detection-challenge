{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://www.kaggle.com/kmader/lung-opacity-classification-transfer-learning/notebook](https://www.kaggle.com/kmader/lung-opacity-classification-transfer-learning/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "323f22eb85744ef15a54946a58a017e52942133e"
   },
   "source": [
    "# Overview\n",
    "The goal is to make a simple Keras model for predicting which category an image falls in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b148e50a8ba9440c2b4ee582496dbf63608cb92c"
   },
   "outputs": [],
   "source": [
    "# params we will probably want to do some hyperparameter optimization later\n",
    "BASE_MODEL= 'VGG16' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
    "IMG_SIZE = (384, 384) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 24 # [1, 8, 16, 24]\n",
    "DENSE_COUNT = 128 # [32, 64, 128, 256]\n",
    "DROPOUT = 0.25 # [0, 0.25, 0.5]\n",
    "LEARN_RATE = 1e-4 # [1e-4, 1e-3, 4e-3]\n",
    "TRAIN_SAMPLES = 8000 # [3000, 6000, 15000]\n",
    "TEST_SAMPLES = 800\n",
    "USE_ATTN = False # [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "image_bbox_df = pd.read_csv('../input/lung-opacity-overview/image_bbox_full.csv')\n",
    "image_bbox_df['path'] = image_bbox_df['path'].map(lambda x: \n",
    "                                                  x.replace('input', \n",
    "                                                            'input/rsna-pneumonia-detection-challenge'))\n",
    "print(image_bbox_df.shape[0], 'images')\n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4925492adb4f55f01794709cb751a42ca5c2177"
   },
   "outputs": [],
   "source": [
    "# get the labels in the right format\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "class_enc = LabelEncoder()\n",
    "image_bbox_df['class_idx'] = class_enc.fit_transform(image_bbox_df['class'])\n",
    "oh_enc = OneHotEncoder(sparse=False)\n",
    "image_bbox_df['class_vec'] = oh_enc.fit_transform(\n",
    "    image_bbox_df['class_idx'].values.reshape(-1, 1)).tolist() \n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b562636a2a48a0557fb16d98841fcbf650245641"
   },
   "source": [
    "# Split into Training and Validation\n",
    "This will give us some feedback on how well our model is doing and if we are overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c12bfd5115610163c2b63ece8fa8845bb7792327"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "image_df = image_bbox_df.groupby('patientId').apply(lambda x: x.sample(1))\n",
    "raw_train_df, valid_df = train_test_split(image_df, test_size=0.25, random_state=2018,\n",
    "                                    stratify=image_df['class'])\n",
    "print(raw_train_df.shape, 'training data')\n",
    "print(valid_df.shape, 'validation data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71c22947c5007a28627b41af14ee8a7f2e990174"
   },
   "source": [
    "## Balance Training Set\n",
    "And reduce the total image count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48b8d60f4435d3ca50d11e12d4eee518c6972ab5"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "raw_train_df.groupby('class').size().plot.bar(ax=ax1)\n",
    "train_df = raw_train_df.groupby('class').\\\n",
    "    apply(lambda x: x.sample(TRAIN_SAMPLES//3)).\\\n",
    "    reset_index(drop=True)\n",
    "train_df.groupby('class').size().plot.bar(ax=ax2) \n",
    "print(train_df.shape[0], 'new training size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9b274bfc403678cd6428b8d245bcb1a08fa0808"
   },
   "source": [
    "## Keras Image Transplantation\n",
    "Since Keras is design for color jpeg images we need to hack a bit to make it dicom friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9548edfc1a318edfcd2a387468a5b7950a376cc5"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # keras 2.2\n",
    "    import keras_preprocessing.image as KPImage\n",
    "except:\n",
    "    # keras 2.1\n",
    "    import keras.preprocessing.image as KPImage\n",
    "    \n",
    "from PIL import Image\n",
    "import pydicom\n",
    "def read_dicom_image(in_path):\n",
    "    img_arr = pydicom.read_file(in_path).pixel_array\n",
    "    return img_arr/img_arr.max()\n",
    "    \n",
    "class medical_pil():\n",
    "    @staticmethod\n",
    "    def open(in_path):\n",
    "        if '.dcm' in in_path:\n",
    "            c_slice = read_dicom_image(in_path)\n",
    "            int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n",
    "            return Image.fromarray(int_slice)\n",
    "        else:\n",
    "            return Image.open(in_path)\n",
    "    fromarray = Image.fromarray\n",
    "KPImage.pil_image = medical_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0d2ca01b3719e94212234b9d3e4ed43520262eb"
   },
   "source": [
    "# Data Augmentation\n",
    "Here we can perform simple augmentation (the `imgaug` and `Augmentation` packages offer much more flexiblity). In order to setup the augmentation we need to know which model we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b655a151895a67cb66b41ccf0bf97c5cd80cc0f2"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "if BASE_MODEL=='VGG16':\n",
    "    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='RESNET52':\n",
    "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='Xception':\n",
    "    from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet169': \n",
    "    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
    "else:\n",
    "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a068b664c8bb465938fa3974c7b6e6120bf0860e"
   },
   "outputs": [],
   "source": [
    "img_gen_args = dict(samplewise_center=False, \n",
    "                              samplewise_std_normalization=False, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range = 0.05, \n",
    "                              width_shift_range = 0.02, \n",
    "                              rotation_range = 3, \n",
    "                              shear_range = 0.01,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range = 0.05,\n",
    "                               preprocessing_function=preprocess_input)\n",
    "img_gen = ImageDataGenerator(**img_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a3983f1be91084ba8c04441280efb18290814f2"
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                              seed = seed,\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values,0)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "720a67aaa3a8f4c9d5d50752c3f18f4e54dc3af0"
   },
   "outputs": [],
   "source": [
    "train_gen = flow_from_dataframe(img_gen, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'class_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_gen = flow_from_dataframe(img_gen, valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'class_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 256) # we can use much larger batches for evaluation\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_X, valid_Y = next(flow_from_dataframe(img_gen, \n",
    "                               valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'class_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = TEST_SAMPLES)) # one big batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "085cf677a4704dce34c679958674a84469e2ef4f"
   },
   "source": [
    "# Show a batch\n",
    "Here we see what the augmentation actually looks like on a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37c9b66822c5dd59162813909c31d384db881026"
   },
   "outputs": [],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "print(t_x.shape, t_y.shape)\n",
    "fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    c_ax.set_title('%s' % class_enc.classes_[np.argmax(c_y)])\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f273320778cca1188e3bf7800248ebf06533c61c"
   },
   "source": [
    "# Build our pretrained model\n",
    "Here we build the pretrained model and download the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ec309826c33787294dd1ba2cac5e4e65bab1755"
   },
   "outputs": [],
   "source": [
    "base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n",
    "                              include_top = False, weights = 'imagenet')\n",
    "base_pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0af654a22993505bd8dc48355c4bd347b89947a"
   },
   "source": [
    "## Model Supplements\n",
    "Here we add a few other layers to the model to make it better suited for the classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0f2055383236d17f0d5455ecc2af5de922fc3b8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers\n",
    "pt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "from keras.layers import BatchNormalization\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "gap = GlobalAveragePooling2D()(bn_features)\n",
    "\n",
    "gap_dr = Dropout(DROPOUT)(gap)\n",
    "dr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'linear', use_bias=False)(gap_dr))\n",
    "dr_steps = BatchNormalization()(dr_steps)\n",
    "dr_steps = layers.LeakyReLU(0.1)(dr_steps)\n",
    "out_layer = Dense(t_y.shape[1], activation = 'softmax')(dr_steps)\n",
    "\n",
    "attn_model = Model(inputs = [pt_features], \n",
    "                   outputs = [out_layer], name = 'trained_model')\n",
    "\n",
    "attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74103ef71c30a9725949fbeed864174cbe62c69d"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "pneu_model = Sequential(name = 'combined_model')\n",
    "base_pretrained_model.trainable = False\n",
    "pneu_model.add(base_pretrained_model)\n",
    "pneu_model.add(attn_model)\n",
    "pneu_model.compile(optimizer = Adam(lr = LEARN_RATE), loss = 'categorical_crossentropy',\n",
    "                           metrics = ['categorical_accuracy'])\n",
    "pneu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f6ff110ed2db877c1daee57de63e7dc16593c0e"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('lung_opacity')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, \n",
    "                                   patience=10, verbose=1, mode='auto', \n",
    "                                   epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58347af9669fed1e5308ac90a6ce06b3579761c5"
   },
   "outputs": [],
   "source": [
    "train_gen.batch_size = BATCH_SIZE\n",
    "pneu_model.fit_generator(train_gen, \n",
    "                         steps_per_epoch=train_gen.n//BATCH_SIZE,\n",
    "                         validation_data=(valid_X, valid_Y), \n",
    "                         epochs=20, \n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08e50876364886ef4a39723055136d741597348a"
   },
   "outputs": [],
   "source": [
    "pneu_model.load_weights(weight_path)\n",
    "pneu_model.save('full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f67dd5726e24517401ff0724f2aa07b1787cf791"
   },
   "outputs": [],
   "source": [
    "pred_Y = pneu_model.predict(valid_X, \n",
    "                          batch_size = BATCH_SIZE, \n",
    "                          verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40f86cabdbea5e8dfc736882c4e7f5036297ec0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "plt.matshow(confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))\n",
    "print(classification_report(np.argmax(valid_Y, -1), \n",
    "                            np.argmax(pred_Y,-1), target_names = class_enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c217311f0f08d5473f493244cc4c4e17c0b6e9d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(np.argmax(valid_Y,-1)==0, pred_Y[:,0])\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
    "ax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(np.argmax(valid_Y,-1)==0, pred_Y[:,0]))\n",
    "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
    "ax1.legend(loc = 4)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate');\n",
    "ax1.set_title('Lung Opacity ROC Curve')\n",
    "fig.savefig('roc_valid.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "cf0f87166720c24ced3b2eae4b2afe77e6529225"
   },
   "source": [
    "# Make a submission\n",
    "We load in the test images and make a submission using those images and a guess for $x, y$ and the width and height for all values where the model is more than 50% convinced there is something suspicious going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c8c27edd01ad87653e2c55284d64fa029afc472"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "sub_img_df = pd.DataFrame({'path': \n",
    "              glob('../input/rsna-pneumonia-detection-challenge/stage_2_test_images/*.dcm')})\n",
    "sub_img_df['patientId'] = sub_img_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "sub_img_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96510ebcc831ef0e9839b4050ba8294c5732fbb3"
   },
   "outputs": [],
   "source": [
    "submission_gen = flow_from_dataframe(img_gen, \n",
    "                                     sub_img_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'patientId', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ac79cbc09dce5a09fd05e021792b5ff26eb658e"
   },
   "source": [
    "## Predict for each image twice and average the results\n",
    "We shouldn't get the same answer since the data are being augmented (here at so-called test-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd564f016278a31bee570f7d6aedc953ca2ff432"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "sub_steps = 2*sub_img_df.shape[0]//BATCH_SIZE\n",
    "out_ids, out_vec = [], []\n",
    "for _, (t_x, t_y) in zip(tqdm(range(sub_steps)), submission_gen):\n",
    "    out_vec += [pneu_model.predict(t_x)]\n",
    "    out_ids += [t_y]\n",
    "out_vec = np.concatenate(out_vec, 0)\n",
    "out_ids = np.concatenate(out_ids, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "527e6c29c66f2de2ec03b53f8de2406b6d051608"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(out_vec, columns=class_enc.classes_)\n",
    "pred_df['patientId'] = out_ids\n",
    "pred_avg_df = pred_df.groupby('patientId').agg('mean').reset_index()\n",
    "pred_avg_df['Lung Opacity'].hist()\n",
    "pred_avg_df.to_csv('image_level_class_probs.csv', index=False) # not hte submission file\n",
    "pred_avg_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c7e5670184b1b9e7de9ad842de6ca671731b057"
   },
   "source": [
    "### Simple Strategy\n",
    "We use the `Lung Opacity` as our confidence and predict the image image. It will hopefully do a little bit better than a trivial baseline, and can be massively improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68ee79e068892d310cc39209517ec20172db8889"
   },
   "outputs": [],
   "source": [
    "pred_avg_df['PredictionString'] = pred_avg_df['Lung Opacity'].map(lambda x: ('%2.2f 0 0 1024 1024' % x) if x>0.5 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d746f6e21788945f5dc19843811a4e9068302255"
   },
   "outputs": [],
   "source": [
    "pred_avg_df[['patientId', 'PredictionString']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
